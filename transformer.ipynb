{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXE7W9jRAZOePpLr+2oBrW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NafuKrypto/NLP/blob/main/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding the inputs"
      ],
      "metadata": {
        "id": "b0YWruLgfnOy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mVqLiE0gfcjG"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.decoder = nn.Linear(d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "TOcra3lffvlv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHmyWMX1iGiY",
        "outputId": "7139280b-68f9-4fbf-f577-466d3f25fca6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.8/dist-packages (0.5.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.26.14)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.13.1+cu116)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "# train_iter was \"consumed\" by the process of building the vocab,\n",
        "# so we have to create it again\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ],
      "metadata": {
        "id": "B9O2aswRiKHP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "# train_iter was \"consumed\" by the process of building the vocab,\n",
        "# so we have to create it again\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ],
      "metadata": {
        "id": "3n6jMmQoiMNZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bptt = 35\n",
        "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        source: Tensor, shape [full_seq_len, batch_size]\n",
        "        i: int\n",
        "\n",
        "    Returns:\n",
        "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
        "        target has shape [seq_len * batch_size]\n",
        "    \"\"\"\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ],
      "metadata": {
        "id": "jDRtxc66j7Te"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ntokens = len(vocab)  # size of vocabulary\n",
        "emsize = 200  # embedding dimension\n",
        "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # number of heads in nn.MultiheadAttention\n",
        "dropout = 0.2  # dropout probability\n",
        "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
      ],
      "metadata": {
        "id": "O6vvJ85-j_PK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0  # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        seq_len = data.size(0)\n",
        "        if seq_len != bptt:  # only on last batch\n",
        "            src_mask = src_mask[:seq_len, :seq_len]\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            seq_len = data.size(0)\n",
        "            if seq_len != bptt:\n",
        "                src_mask = src_mask[:seq_len, :seq_len]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ],
      "metadata": {
        "id": "tLG8jiLNkBz3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 3\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        train(model)\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "        print('-' * 89)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBeyV7IDkFHL",
        "outputId": "cd79a3c7-2f7b-4334-b4c0-8d2570ef667d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 599.09 | loss  8.25 | ppl  3836.73\n",
            "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 584.25 | loss  6.92 | ppl  1008.74\n",
            "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 602.20 | loss  6.46 | ppl   639.39\n",
            "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 585.30 | loss  6.32 | ppl   555.23\n",
            "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 592.07 | loss  6.20 | ppl   490.62\n",
            "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 588.80 | loss  6.16 | ppl   471.65\n",
            "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 588.68 | loss  6.12 | ppl   453.40\n",
            "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 598.04 | loss  6.11 | ppl   448.37\n",
            "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 596.53 | loss  6.03 | ppl   414.22\n",
            "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 599.28 | loss  6.02 | ppl   412.77\n",
            "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 612.15 | loss  5.89 | ppl   362.97\n",
            "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 612.02 | loss  5.97 | ppl   390.62\n",
            "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 621.32 | loss  5.96 | ppl   385.82\n",
            "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 639.41 | loss  5.89 | ppl   359.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 1824.55s | valid loss  5.78 | valid ppl   323.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 647.41 | loss  5.87 | ppl   354.19\n",
            "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 639.82 | loss  5.86 | ppl   349.35\n",
            "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 645.43 | loss  5.66 | ppl   287.95\n",
            "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 659.03 | loss  5.70 | ppl   298.01\n",
            "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 654.44 | loss  5.65 | ppl   284.10\n",
            "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 654.35 | loss  5.67 | ppl   291.07\n",
            "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 664.17 | loss  5.68 | ppl   293.90\n",
            "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 668.54 | loss  5.71 | ppl   301.01\n",
            "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 666.00 | loss  5.65 | ppl   284.09\n",
            "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 672.26 | loss  5.66 | ppl   288.55\n",
            "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 662.18 | loss  5.55 | ppl   256.96\n",
            "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 665.42 | loss  5.65 | ppl   284.12\n",
            "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 662.74 | loss  5.65 | ppl   283.83\n",
            "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 659.57 | loss  5.57 | ppl   262.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 1991.24s | valid loss  5.67 | valid ppl   289.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 669.05 | loss  5.60 | ppl   269.12\n",
            "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 665.50 | loss  5.62 | ppl   276.43\n",
            "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 664.44 | loss  5.41 | ppl   224.58\n",
            "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 657.20 | loss  5.48 | ppl   238.70\n",
            "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 661.13 | loss  5.44 | ppl   229.88\n",
            "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 644.98 | loss  5.47 | ppl   238.33\n",
            "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 661.30 | loss  5.48 | ppl   240.46\n",
            "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 646.98 | loss  5.51 | ppl   247.37\n",
            "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 648.82 | loss  5.47 | ppl   236.29\n",
            "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 642.67 | loss  5.48 | ppl   239.35\n",
            "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 636.40 | loss  5.36 | ppl   211.69\n",
            "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 634.79 | loss  5.46 | ppl   235.31\n",
            "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 642.10 | loss  5.47 | ppl   237.47\n",
            "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 643.01 | loss  5.40 | ppl   221.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 1965.80s | valid loss  5.58 | valid ppl   264.11\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluate(model, test_data)\n",
        "test_ppl = math.exp(test_loss)\n",
        "print('=' * 89)\n",
        "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
        "      f'test ppl {test_ppl:8.2f}')\n",
        "print('=' * 89)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLomkHkqkK1L",
        "outputId": "43ff2369-de44-4fd4-efb3-1c9d2f653808"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  5.49 | test ppl   242.09\n",
            "=========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtaK38EUkgaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}